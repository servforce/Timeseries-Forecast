import asyncio
import json
import os

# =========================================================
# ğŸ›‘ å¼ºåˆ¶ä¿®å¤ï¼šåœ¨å¯¼å…¥ä»»ä½•ç½‘ç»œåº“ä¹‹å‰ï¼Œå±è”½æ‰€æœ‰ä»£ç†è®¾ç½®
# =========================================================
os.environ["NO_PROXY"] = "localhost,127.0.0.1,0.0.0.0"
os.environ["http_proxy"] = ""
os.environ["https_proxy"] = ""
os.environ["HTTP_PROXY"] = ""
os.environ["HTTPS_PROXY"] = ""

import ollama
from mcp import ClientSession, StdioServerParameters
from mcp.client.sse import sse_client
from mcp.types import CallToolResult, GetPromptResult

# é…ç½®ä½ çš„æœåŠ¡åœ°å€
CHRONOS_MCP_URL = "http://localhost:5001/mcp/sse"
MODEL_NAME = "qwen2.5" 

async def run_agent():
    print(f"ğŸ”— æ­£åœ¨è¿æ¥ Chronos MCP æœåŠ¡: {CHRONOS_MCP_URL} ...")
    
    try:
        async with sse_client(CHRONOS_MCP_URL) as streams:
            async with ClientSession(streams[0], streams[1]) as session:
                print("âœ… MCP æœåŠ¡è¿æ¥æˆåŠŸï¼")
                
                await session.initialize()
                
                # ====================================================
                # ğŸš€ æ­¥éª¤ 1: ä»æœåŠ¡ç«¯è·å– Prompt (æŒ‡ä»¤)
                # ====================================================
                print("\nğŸ“¥ [1/3] æ­£åœ¨è·å–æç¤ºè¯æ¨¡ç‰ˆ (Prompts)...")
                try:
                    prompt_name = "chronos_forecast_guide" 
                    prompt_result: GetPromptResult = await session.get_prompt(
                        name=prompt_name,
                        arguments={} 
                    )
                    server_system_prompt = prompt_result.messages[0].content.text
                    print(f"   âœ… åŠ è½½æˆåŠŸ: {prompt_name} (é•¿åº¦: {len(server_system_prompt)})")
                except Exception as e:
                    print(f"   âš ï¸ è·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å›é€€: {e}")
                    server_system_prompt = "ä½ æ˜¯é¢„æµ‹åŠ©æ‰‹ï¼Œè¯·ä½¿ç”¨ timestamp å’Œ target å­—æ®µã€‚"

                # ====================================================
                # ğŸ“š æ­¥éª¤ 2: ä»æœåŠ¡ç«¯æ‹‰å–èµ„æº (Resources)
                # èµ„æºé€šå¸¸åŒ…å«æ•°æ®æ ¼å¼æ ·ä¾‹ï¼Œè¿™å¯¹äºæ•™ä¼šæ¨¡å‹æ­£ç¡®æ„é€ å‚æ•°è‡³å…³é‡è¦
                # ====================================================
                print("\nğŸ“¥ [2/3] æ­£åœ¨æ‹‰å–å‚è€ƒèµ„æº (Resources)...")
                resource_context_str = ""
                try:
                    # A. åˆ—å‡ºæ‰€æœ‰å¯ç”¨èµ„æº
                    resources_list = await session.list_resources()
                    if resources_list.resources:
                        print(f"   ğŸ” å‘ç° {len(resources_list.resources)} ä¸ªèµ„æº")
                        
                        # B. éå†å¹¶è¯»å–æ¯ä¸ªèµ„æºçš„å†…å®¹
                        res_contents = []
                        for res in resources_list.resources:
                            print(f"   - è¯»å–: {res.name} ({res.uri})")
                            try:
                                # è¯»å–èµ„æºå®ä½“
                                read_res = await session.read_resource(res.uri)
                                # æå–æ–‡æœ¬å†…å®¹
                                content = read_res.contents[0].text
                                res_contents.append(f"\n--- å‚è€ƒèµ„æ–™: {res.name} ---\n{content}\n")
                            except Exception as e:
                                print(f"     âŒ è¯»å–å¤±è´¥: {e}")
                        
                        # C. æ‹¼æ¥èµ„æºå†…å®¹
                        resource_context_str = "\n".join(res_contents)
                    else:
                        print("   âš ï¸ æœåŠ¡ç«¯æœªæä¾›ä»»ä½•èµ„æº")

                except Exception as e:
                    print(f"   âš ï¸ èµ„æºæ‹‰å–è¿‡ç¨‹å‡ºé”™: {e}")

                # ====================================================
                # ğŸ› ï¸ æ­¥éª¤ 3: è·å–å·¥å…·å®šä¹‰ (Tools)
                # ====================================================
                print("\nğŸ“¥ [3/3] æ­£åœ¨åŒæ­¥å·¥å…·åˆ—è¡¨ (Tools)...")
                tools_result = await session.list_tools()
                mcp_tools = tools_result.tools
                ollama_tools = []
                for tool in mcp_tools:
                    ollama_tools.append({
                        "type": "function",
                        "function": {
                            "name": tool.name,
                            "description": tool.description,
                            "parameters": tool.inputSchema
                        }
                    })
                print(f"   âœ… å·²åŠ è½½ {len(ollama_tools)} ä¸ªå·¥å…·")

                # ====================================================
                # ğŸ§  æ„å»ºæœ€ç»ˆçš„ç³»ç»Ÿä¸Šä¸‹æ–‡
                # System Prompt = æŒ‡ä»¤ (Prompt) + å‚è€ƒèµ„æ–™ (Resources)
                # ====================================================
                final_system_content = server_system_prompt
                if resource_context_str:
                    final_system_content += "\n\nã€é‡è¦å‚è€ƒæ•°æ®/æ ¼å¼æ ·ä¾‹ã€‘\n" + resource_context_str
                
                messages = [{"role": "system", "content": final_system_content}]
                
                print("\n" + "="*50)
                print("ğŸ¤– Agent å·²å°±ç»ª (è¾“å…¥ 'quit' é€€å‡º)")
                print("="*50)

                # ---------------------------------------------------------
                # äº¤äº’å¾ªç¯
                # ---------------------------------------------------------
                while True:
                    user_input = input("\nğŸ‘¤ ä½ : ")
                    if user_input.lower() in ['quit', 'exit']:
                        break

                    messages.append({"role": "user", "content": user_input})

                    # A. è¯·æ±‚ Ollama
                    response = ollama.chat(
                        model=MODEL_NAME,
                        messages=messages,
                        tools=ollama_tools,
                    )
                    
                    # B. å¤„ç†å·¥å…·è°ƒç”¨
                    if response.message.tool_calls:
                        messages.append(response.message)
                        
                        for tool_call in response.message.tool_calls:
                            func_name = tool_call.function.name
                            func_args = tool_call.function.arguments
                            
                            print(f"âš™ï¸  æ¨¡å‹è¯·æ±‚è°ƒç”¨å·¥å…·: {func_name} ...")
                            print(f"   å‚æ•°: {json.dumps(func_args, ensure_ascii=False)[:100]}...")

                            try:
                                result: CallToolResult = await session.call_tool(
                                    name=func_name,
                                    arguments=func_args
                                )
                                
                                tool_output = result.content[0].text
                                print("âœ… å·¥å…·è°ƒç”¨æˆåŠŸ")

                            except Exception as e:
                                tool_output = f"Error calling tool: {str(e)}"
                                print(f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {e}")

                            messages.append({
                                "role": "tool",
                                "content": tool_output,
                            })

                        # C. è·å–æœ€ç»ˆå›ç­”
                        final_response = ollama.chat(
                            model=MODEL_NAME,
                            messages=messages,
                        )
                        print(f"\nğŸ¤– Agent: {final_response.message.content}")
                        messages.append(final_response.message)

                    else:
                        print(f"\nğŸ¤– Agent: {response.message.content}")
                        messages.append(response.message)

    except Exception as e:
        print(f"\nâŒ è¿è¡Œé”™è¯¯: {e}")

if __name__ == "__main__":
    asyncio.run(run_agent())